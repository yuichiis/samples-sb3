# A2Cハイパーパラメータ感度分析レポート (`Pendulum-v1`)

## 1. 概要

本レポートは、`Pendulum-v1`環境におけるA2Cアルゴリズムの性能に対し、主要なハイパーパラメータがどの程度影響を与えるかを調査した結果をまとめたものである。

`stable-baselines3/rl-zoo`で提供されている設定をベースラインとし、6つの主要なハイパーパラメータを個別に変更して性能を測定した。さらに、影響の大きかった変更について、PyTorchによる自社実装でも同様の傾向が見られるかを追加で検証した。

結論として、**`normalize_advantage`の無効化**、**線形の学習率スケジュール**、**`use_sde`の有効化**、そして**`ent_coef`を0に設定**することが、本タスクの成功に極めて重要な要因であることが判明した。ベースラインとして採用した`rl-zoo`の設定は、これらの要素を適切に組み合わせており、非常に効果的であることが実証された。

## 2. 実験設定

- **アルゴリズム**: A2C (Advantage Actor-Critic)
- **環境**: `Pendulum-v1`
- **総タイムステップ数**: 400,000
- **評価指標**: 
  - **SB3版**: 学習中に`EvalCallback`によって記録された、評価エピソードにおけるベスト平均報酬。
  - **PyTorch版**: 学習終了時点での直近100エピソードの平均報酬。

### ベースライン・ハイパーパラメータ (SB3)

```python
hyperparams = {
    "policy": "MlpPolicy",
    "n_steps": 8,
    "gamma": 0.9,
    "gae_lambda": 0.9,
    "ent_coef": 0.0,
    "vf_coef": 0.4,
    "max_grad_norm": 0.5,
    "use_sde": True,
    "normalize_advantage": False,
    "policy_kwargs": dict(log_std_init=-2, ortho_init=False),
}
learning_rate = "linear_schedule(7e-4)" # 線形に7e-4から0へ減衰
```

## 3. Stable Baselines3による実験結果

| 実験項目 | 変更内容 | ベスト平均報酬 | ベースラインからの変化 | 影響度 |
| :--- | :--- | :--- | :--- | :--- |
| **ベースライン** | (変更なし) | **-27.02** | - | - |
| `normalize_advantage` | `False` → `True` | -1471.63 | **-1444.61** | **極めて大きい (悪化)** |
| `ent_coef` | `0.0` → `0.01` | -313.44 | **-286.42** | **非常に大きい (悪化)** |
| 学習率スケジュール | 線形減衰 → 固定 | -277.13 | **-250.11** | **非常に大きい (悪化)** |
| `use_sde` | `True` → `False` | -109.38 | -82.36 | 大きい (悪化) |
| `ortho_init` | `False` → `True` | -76.12 | -49.10 | 中程度 (悪化) |
| `gae_lambda` | `0.9` → `1.0` | -27.13 | -0.11 | ほぼ影響なし |

## 4. PyTorch実装による追加検証

SB3での実験で特に影響が大きかった`normalize_advantage`と`ent_coef`の変更について、PyTorchで簡易的に実装したA2Cコードでも同様の傾向が見られるか検証した。

### PyTorch版 実験結果

| 実験項目 | 変更内容 | 最終平均報酬 | ベースラインからの変化 |
| :--- | :--- | :--- | :--- |
| **PyTorchベースライン** | (変更なし) | **-1092.20** | - |
| `normalize_advantage` | `False` → `True` | -1450.77 | **-358.57 (悪化)** |
| `ent_coef` | `0.0` → `0.01` | -1337.99 | **-245.79 (悪化)** |

PyTorch実装においても、`normalize_advantage`の有効化と`ent_coef`の追加が性能を大きく悪化させることが確認できた。これにより、これらのハイパーパラメータへの感度はSB3ライブラリ固有のものではなく、A2CアルゴリズムとPendulum環境の組み合わせに起因するものである可能性が高いことが示唆された。

## 5. 再現性の確認

学習の信頼性を担保するため、SB3版とPyTorch版のベースライン実験を再度実施した。

- **SB3ベースライン (再実験)**:
  - **ベスト平均報酬: -79.07**
  - 初回実験の-27.02よりは低いものの、他の実験と比較すると依然として高いスコアであり、ベースライン設定の有効性が改めて確認された。強化学習の確率的な性質により、結果にはある程度のばらつきが生じる。

- **PyTorchベースライン (再実験)**:
  - **最終平均報酬: -1092.20**
  - 乱数シードを固定しているため、初回と完全に同一の結果が得られた。これにより、PyTorch版のコードにおける学習の挙動が決定論的であり、再現性があることが確認された。

## 6. 総合結論

一連の実験を通じて、`rl-zoo`で提供されているA2Cのハイパーパラメータ設定が、`Pendulum-v1`環境において非常に効果的であることが実証された。

特に、**Advantageを正規化せず (`normalize_advantage=False`)**、**学習率をスケジュールし**、**状態依存探索を有効にする (`use_sde=True`)** という3つの要素が、高い性能を達成するための最も重要な鍵であった。

これらの知見は、A2Cを他のタスクに応用する際の重要な指針となるだろう。