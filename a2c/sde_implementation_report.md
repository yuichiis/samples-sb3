# PyTorch版A2C 性能改善に向けた追加検証レポート

## 1. 概要

先の「A2Cハイパーパラメータ感度分析レポート」において、Stable Baselines3（SB3）で実装されたA2Cが`Pendulum-v1`環境で高い性能を発揮することが確認された。しかし、その主要なハイパーパラメータを模倣してPyTorchで実装したA2Cは、SB3版の性能に遠く及ばなかった。

本レポートは、この性能差の原因を特定するため、以下の追加検証を行った結果をまとめたものである。

1.  **`seed`値変更による堅牢性の検証**: SB3版とPyTorch版の学習成功が、特定の乱数シードに依存していないかを確認した。
2.  **`RMSProp`パラメータの調査**: 両実装で使用されているオプティマイザのパラメータに差異がないかを確認した。
3.  **SDE（状態依存探索）の実装と検証**: 性能差の最大の要因と仮説立てられたSDEをPyTorch版に実装し、その効果を測定した。

## 2. `seed`値変更による堅牢性の検証

### 2.1. SB3版

`seed=43`のベースライン設定に対し、`seed=123`で再実験を行った。

| seed値 | ベスト平均報酬 |
| :--- | :--- |
| 43 (初回) | -27.02 |
| 43 (再実験) | -79.07 |
| 123 | -54.92 |

**考察**:
シード値を変更しても、報酬が-1500前後から大幅に改善し、安定して高いスコア（-27 ~ -79）を達成した。これにより、**SB3版のベースライン設定は特定のシードに依存せず、堅牢に学習を成功させる能力がある**ことが確認された。

### 2.2. PyTorch版

`seed=43`で学習の改善が見られたPyTorch版に対し、`seed=123`で再実験を行った。

| seed値 | 最終平均報酬 |
| :--- | :--- |
| 43 | -1092.20 |
| 123 | -1389.09 |

**考察**:
`seed=43`では報酬の改善が見られたのに対し、`seed=123`では学習がほぼ停滞した。この結果は、**PyTorch版の現状の実装が不安定であり、学習が成功するかどうかが乱数シードに大きく依存している**ことを示唆している。

## 3. `RMSProp`パラメータの調査

SB3のソースコード (`stable_baselines3/a2c/a2c.py`) を調査し、オプティマイザ`RMSProp`のパラメータをPyTorch版と比較した。

**調査結果**:
SB3が使用する`RMSProp`の主要パラメータは `alpha=0.99`, `eps=1e-5` であり、これはPyTorch版の実装と完全に一致していた。

**結論**:
オプティマイザの**パラメータ設定の違いが性能差の原因である可能性は低い**と判断した。

## 4. SDE (状態依存探索) の実装と検証

性能差の最大の要因と仮説を立て、SB3の`StateDependentNoiseDistribution`クラスのロジックを参考に、PyTorch版にSDEを実装した。

- **実装**: 状態特徴量（`latent_sde`）を入力としてノイズを生成する`StateDependentNoiseDistribution`クラスを新設し、SB3の計算フローを忠実に再現した。
- **テスト結果**:
  - **最終平均報酬: -1314.31**

**考察**:
SDEの実装は成功し、エラーなく学習を完了できた。学習曲線を見ると、報酬は-1400台から-1300前後まで改善しており、学習自体は進んでいる。

しかし、その改善幅はSDE非搭載のベースライン（-1092.20）を超えるものではなく、SB3版のスコア（-27 ~ -79）には遠く及ばなかった。この結果は、**SB3版とPyTorch版の性能差の原因が、SDEの実装の有無だけではない**ことを強く示唆している。

## 5. 総合結論と今後の展望

一連の検証の結果、PyTorch版の性能がSB3版に及ばない理由は、単一のハイパーパラメータやSDEの有無といった単純な要因だけでは説明できないことが明らかになった。

学習の成否がシード値に依存する不安定さや、SDEを実装しても性能が頭打ちになるという事実は、より根本的な実装上の差異が存在することを示している。考えられる残りの要因は以下の通りである。

1.  **`RMSProp`の内部実装**: パラメータは同じでも、PyTorchとSB3（内部のPyTorch）でのオプティマイザの更新ロジックに微妙な差異が存在する可能性。
2.  **ネットワークの重み初期化**: SB3が内部で行っているデフォルトの初期化処理が、PyTorchのそれとは異なる可能性。
3.  **その他の実装詳細**: `RolloutBuffer`の処理、勾配計算・クリッピングの適用方法など、フレームワークレベルでの細かな実装の違い。

**結論**:
Stable Baselines3のような最適化された強化学習フレームワークの性能をスクラッチから再現するには、表面的なアルゴリズムの流れだけでなく、オプティマイザや層の初期化といった、フレームワーク内部の細かな実装ディテールまでを忠実に模倣する必要がある。今回の検証は、その難しさと奥深さを示す貴重なケーススタディとなった。
